{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JumsFSYfL6J",
        "outputId": "603252b8-c474-42a8-a643-a2bca8396b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKeJwe1EfpFN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import GlorotNormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEO7QzBtfJUC",
        "outputId": "444e97b9-976b-4412-8ecc-a6e3e497c041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained ResNet50 model\n",
        "base_model = tf.keras.models.load_model('/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/1-Backbone/ResNet50/resnet50_adamax_v1_kaggle.h5')\n",
        "\n",
        "#Weight initalization = Adam optimization -> acelera convergencia, distribuyendo los pesos inciales uniformemente en un rango especifico\n",
        "initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "# Step 2: Remove the last few layers\n",
        "# We remove 2 layers because one is the Dense classification layer, and the other one is the Global Pooling Avg. It is recommended to eliminate this one also\n",
        "# because it averages along the 3D coming from the convolutional layer, so some spatial information is missing.\n",
        "base_model = models.Model(inputs=base_model.input, outputs=base_model.layers[-4].output)\n",
        "\n",
        "# Step 3: Add ConvLSTM layers for temporal feature extraction\n",
        "# Assuming the input shape for each frame is (224, 224, 3)\n",
        "# Adjust the input shape accordingly based on the actual input shape for your video frames\n",
        "input_shape = (None, 224, 224, 3)  # (time_steps, height, width, channels)\n",
        "video_input = layers.Input(shape=input_shape)\n",
        "\n",
        "x = layers.TimeDistributed(base_model)(video_input)\n",
        "x = layers.Reshape((-1, 1, 1, 2048))(x)  # Adding spatial dimensions\n",
        "\n",
        "#The ConvLSTM layers used consist of 64 neurons each, a kernel size of 3 Ã— 3, a dropout of 0.2 and a recurrent dropout of 0.1.\n",
        "#x = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True)(x)\n",
        "x = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', dropout=0.2, recurrent_dropout=0.1, kernel_initializer=initializer, return_sequences=True)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
        "x = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), dropout=0.2, recurrent_dropout=0.1, kernel_initializer=initializer, padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Step 4: Add a dense layer for binary classification\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(400, activation='tanh', kernel_initializer=initializer)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(100, activation='tanh', kernel_initializer=initializer)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "output = layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)(x)\n",
        "\n",
        "# Step 5: Compile and build the model\n",
        "model = models.Model(inputs=video_input, outputs=output)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary to verify the architecture\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QEm05B2TiRC",
        "outputId": "2f746f92-5d6f-407a-e1f5-af05bffc20bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+----------------+\n",
            "| Set Name   |   Siniestro |   No Siniestro |\n",
            "+============+=============+================+\n",
            "| train      |         338 |           1351 |\n",
            "+------------+-------------+----------------+\n",
            "| val        |          17 |             67 |\n",
            "+------------+-------------+----------------+\n",
            "| test       |          68 |            272 |\n",
            "+------------+-------------+----------------+\n"
          ]
        }
      ],
      "source": [
        "# Checking how many videos do we have in Dataset\n",
        "\n",
        "import os\n",
        "from tabulate import tabulate\n",
        "\n",
        "def count_folders(dataset_path):\n",
        "    # Define the set names and class names\n",
        "    set_names = [\"train\", \"val\", \"test\"]\n",
        "    class_names = [\"Siniestro\", \"No Siniestro\"]\n",
        "\n",
        "    # Create a dictionary to hold the counts\n",
        "    counts = {set_name: {class_name: 0 for class_name in class_names} for set_name in set_names}\n",
        "\n",
        "    # Iterate through the dataset, counting the folders\n",
        "    for set_name in set_names:\n",
        "        for class_name in class_names:\n",
        "            class_set_path = os.path.join(dataset_path, class_name, set_name)\n",
        "            folder_count = sum(1 for entry in os.scandir(class_set_path) if entry.is_dir())\n",
        "            counts[set_name][class_name] = folder_count\n",
        "\n",
        "    return counts\n",
        "\n",
        "def print_table(counts):\n",
        "    # Prepare the table data\n",
        "    headers = [\"Set Name\"] + list(counts[\"train\"].keys())\n",
        "    table_data = [[set_name] + list(counts[set_name].values()) for set_name in counts.keys()]\n",
        "\n",
        "    # Print the table\n",
        "    print(tabulate(table_data, headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Usage:\n",
        "dataset_path = \"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Dataset\"\n",
        "counts = count_folders(dataset_path)\n",
        "print_table(counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_MIZO_tWBKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88095fcd-1907-4cd6-d70f-fabccd5619fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Siniestro folder: 4.62 GB\n",
            "Size of No Siniestro folder: 0.00 GB\n"
          ]
        }
      ],
      "source": [
        "# Size of the Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "def get_size(path):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size / (1024 ** 3)  # Convert bytes to gigabytes\n",
        "\n",
        "def main():\n",
        "    dataset_path = \"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Dataset\"\n",
        "    classes = [\"Siniestro\", \"No Siniestro\"]\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        size_gb = get_size(class_path)\n",
        "        print(f\"Size of {class_name} folder: {size_gb:.2f} GB\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlWtrBxzheMh"
      },
      "source": [
        "## Load preprocessed file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1FguDlyKKeX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_20kO3eUJ-X1"
      },
      "outputs": [],
      "source": [
        "data = np.load(\"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Preprocess ResNet/data/preprocessed_data_Resnet_FINAL.npz\", allow_pickle=True)\n",
        "labels = np.load(\"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Preprocess ResNet/labels/preprocessed_labels_Resnet_FINAL.npz\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "547iYUWWBFU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c691847-adea-4408-ac86-9503f853b546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train', 'test', 'val']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, (480, 45, 224, 224, 3), (96, 45, 224, 224, 3), (24, 45, 224, 224, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(data.files), data['train'].shape, data['test'].shape, data['val'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx3G7QdenFrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a646cb2e-c133-4a6b-a8ea-95ce7442b62f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((480,), (96,), (24,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "labels['train'].shape, labels['test'].shape, labels['val'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOBdsILE23lX"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRwGUuVeI9sO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3e132c-2536-405b-97cb-939e584fb4af"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "120/120 [==============================] - 977s 8s/step - loss: 0.6448 - accuracy: 0.6562 - val_loss: 0.6039 - val_accuracy: 0.7083\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 982s 8s/step - loss: 0.5098 - accuracy: 0.7542 - val_loss: 0.3769 - val_accuracy: 0.9583\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 962s 8s/step - loss: 0.4046 - accuracy: 0.8188 - val_loss: 0.2609 - val_accuracy: 0.9167\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 922s 8s/step - loss: 0.3482 - accuracy: 0.8562 - val_loss: 0.1326 - val_accuracy: 0.9583\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 918s 8s/step - loss: 0.2684 - accuracy: 0.8917 - val_loss: 0.1832 - val_accuracy: 0.9583\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 924s 8s/step - loss: 0.3064 - accuracy: 0.8708 - val_loss: 0.2307 - val_accuracy: 0.9167\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 919s 8s/step - loss: 0.3095 - accuracy: 0.8667 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 897s 7s/step - loss: 0.2924 - accuracy: 0.8792 - val_loss: 0.2280 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 915s 8s/step - loss: 0.1890 - accuracy: 0.9396 - val_loss: 0.1687 - val_accuracy: 0.9167\n",
            "Epoch 10/10\n",
            "112/120 [===========================>..] - ETA: 59s - loss: 0.1870 - accuracy: 0.9308 "
          ]
        }
      ],
      "source": [
        "# Convert the list of numpy arrays to a single numpy array for training\n",
        "X_train = np.array(data[\"train\"])\n",
        "y_train = np.array(labels[\"train\"])  # You would need to convert labels to a numerical format\n",
        "\n",
        "X_val = np.array(data[\"val\"])\n",
        "y_val = np.array(labels[\"val\"])  # You would need to convert labels to a numerical format\n",
        "\n",
        "# Train your model\n",
        "#model.fit(X_train, y_train, epochs=30, batch_size=5, validation_data=(X_val, y_val))\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=4, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC-OHrXggAM7"
      },
      "outputs": [],
      "source": [
        "# Save model weights\n",
        "model.save('/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/modelo_final_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_B4isaUJe9J"
      },
      "outputs": [],
      "source": [
        "# Back up save (in case model doesn't save due to storage in drive not enough)\n",
        "model.save('/content/modelo_final_resnet50.h5')\n",
        "from google.colab import files\n",
        "files.download('/content/modelo_final_resnet50.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AfQZuPGX7TR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bCiFSTCBNKO"
      },
      "outputs": [],
      "source": [
        "X_test = np.array(data[\"test\"])\n",
        "y_test = np.array(labels[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEzqRn9SA8VX",
        "outputId": "c8034b0b-afa3-4478-bb3e-a7b43adbc26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 68s 22s/step - loss: 0.1477 - accuracy: 0.9583\n",
            "Test Loss: 0.1477\n",
            "Test Accuracy: 0.9583\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def save_history_to_csv(history, filename):\n",
        "    # Ensure the history object is not None\n",
        "    if history is None:\n",
        "        print(\"No history data to save.\")\n",
        "        return\n",
        "\n",
        "    # Open the file in write mode\n",
        "    with open(filename, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header\n",
        "        headers = ['epoch'] + list(history.history.keys())\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        # Write the data\n",
        "        for epoch in range(len(history.history['loss'])):\n",
        "            row = [epoch + 1]  # epochs are zero-indexed in history\n",
        "            for metric in history.history:\n",
        "                row.append(history.history[metric][epoch])\n",
        "            writer.writerow(row)\n",
        "\n",
        "    print(f\"History saved to {filename}\")\n",
        "\n",
        "save_history_to_csv(history, '/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Metrics/training_history_resnet50.csv')"
      ],
      "metadata": {
        "id": "dEJJbA-ymMit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reload final model for metrics"
      ],
      "metadata": {
        "id": "EmusGJyplsgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/modelo_final_resnet50.h5'\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "id": "8iZ1i3grlujh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(data[\"test\"])\n",
        "y_test = np.array(labels[\"test\"])"
      ],
      "metadata": {
        "id": "OcG1K8TymyZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "bemrWa_PmyZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8375414-a25a-4ac3-f280-7679397fc665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 86s 27s/step - loss: 0.1477 - accuracy: 0.9583\n",
            "Test Loss: 0.1477\n",
            "Test Accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other metrics"
      ],
      "metadata": {
        "id": "1CLdBvHUtvSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "DgK_QC1mtuHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1) # esta linea esta mal\n",
        "\n",
        "y_true = y_test"
      ],
      "metadata": {
        "id": "dLo-tBHwtwXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b43580-5b01-4b17-d32d-dd4365342dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 94s 30s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_pred: \", y_pred)"
      ],
      "metadata": {
        "id": "sZKHnJC5ZpsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_round = np.round(y_pred , decimals=0)\n",
        "y_pred_round"
      ],
      "metadata": {
        "id": "yQo0i0JPsteX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_true: \", y_true)"
      ],
      "metadata": {
        "id": "QLv_OefEZ5tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16bf17c8-2857-4eb7-d025-73db01be8ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Precision, Recall and F1 score\n",
        "report = classification_report(y_true, y_pred_round , output_dict=True)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKn0Yaaot15n",
        "outputId": "2007b479-f441-4f6d-f873-d0b2a8fdd570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.9545454545454546, 'recall': 0.984375, 'f1-score': 0.9692307692307692, 'support': 64}, '1': {'precision': 0.9666666666666667, 'recall': 0.90625, 'f1-score': 0.9354838709677419, 'support': 32}, 'accuracy': 0.9583333333333334, 'macro avg': {'precision': 0.9606060606060607, 'recall': 0.9453125, 'f1-score': 0.9523573200992556, 'support': 96}, 'weighted avg': {'precision': 0.9585858585858587, 'recall': 0.9583333333333334, 'f1-score': 0.9579818031430934, 'support': 96}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = '/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Metrics/other_metrics_resnet50.csv'\n",
        "report_df.to_csv(csv_file_path, index=True)\n",
        "\n",
        "print(f\"Classification report saved to {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH5v0QCzvHsg",
        "outputId": "7418f599-6184-49cd-a946-00048cf0467d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report saved to /content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Metrics/other_metrics_resnet50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC curve"
      ],
      "metadata": {
        "id": "qGLQoit7jhPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/modelo_final_resnet50.h5'\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "id": "rrdHxgs6oSr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBu8b9LoSr9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oimkhr1oSr9"
      },
      "outputs": [],
      "source": [
        "data = np.load(\"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Preprocess ResNet/data/preprocessed_data_Resnet_FINAL.npz\", allow_pickle=True)\n",
        "labels = np.load(\"/content/drive/MyDrive/Tesis_maestria_DS/Tesis/Proceso/2-Entrenamiento/2-Modelo completo/Preprocess ResNet/labels/preprocessed_labels_Resnet_FINAL.npz\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(data[\"test\"])\n",
        "y_test = np.array(labels[\"test\"])"
      ],
      "metadata": {
        "id": "8C5WJwBxoSr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_true = y_test"
      ],
      "metadata": {
        "id": "lNZUL2OZoYv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_round = np.round(y_pred , decimals=0)"
      ],
      "metadata": {
        "id": "xPzzYkozoYv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, roc_curve, auc"
      ],
      "metadata": {
        "id": "I0Xu3HYGj9Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_pred_round)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r47oi3ijdlEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}